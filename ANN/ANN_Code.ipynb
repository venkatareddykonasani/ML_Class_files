{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN_Code.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP56Bp9uFkIuLPeDcjQUoye"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fFQgxtRPaoQI"},"source":["ANN\n","\n","[statinfer.com](https://statinfer.com/)"]},{"cell_type":"code","metadata":{"id":"QAbXOBIsaTPU"},"source":["import pandas as pd\n","Emp_Purchase_raw = pd.read_csv(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/Emp_Purchase/Emp_Purchase.csv\")\n","Emp_Purchase_raw.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wACk7Xy5bdod"},"source":["####Filter the data and take a subset from above dataset . Filter condition is Sample_Set<3\n","\n","Emp_Purchase1=Emp_Purchase_raw[Emp_Purchase_raw.Sample_Set<3]\n","Emp_Purchase1.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP_oIcJZbkoN"},"source":["####The clasification graph\n","#Draw a scatter plot that shows Age on X axis and Experience on Y-axis. Try to distinguish the two classes with colors or shapes.\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(111)\n","\n","ax1.scatter(Emp_Purchase1.Age[Emp_Purchase1.Purchase==0],Emp_Purchase1.Experience[Emp_Purchase1.Purchase==0], s=100, c='b', marker=\"o\", label='Purchase 0')\n","ax1.scatter(Emp_Purchase1.Age[Emp_Purchase1.Purchase==1],Emp_Purchase1.Experience[Emp_Purchase1.Purchase==1], s=100, c='r', marker=\"+\", label='Purchase 1')\n","\n","plt.xlim(min(Emp_Purchase1.Age), max(Emp_Purchase1.Age))\n","plt.ylim(min(Emp_Purchase1.Experience), max(Emp_Purchase1.Experience))\n","plt.legend(loc='upper left');\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"piqU1oAkbqPp"},"source":["# Logistic Regerssion - Decisio Boundary"]},{"cell_type":"code","metadata":{"id":"sTcAJJImbnzv"},"source":["import statsmodels.formula.api as sm\n","model1 = sm.logit(formula='Purchase ~ Age+Experience', data=Emp_Purchase1)\n","fitted1 = model1.fit()\n","print(fitted1.summary2())\n","\n","#######Accuracy and error of the model1\n","#Create the confusion matrix\n","predicted_values=fitted1.predict(Emp_Purchase1[[\"Age\"]+[\"Experience\"]])\n","predicted_values[1:10]\n","threshold=0.5\n","\n","import numpy as np\n","predicted_class=np.zeros(predicted_values.shape)\n","predicted_class[predicted_values>threshold]=1\n","\n","from sklearn.metrics import confusion_matrix as cm\n","ConfusionMatrix = cm(Emp_Purchase1[['Purchase']],predicted_class)\n","print(\"ConfusionMatrix \\n\",ConfusionMatrix)\n","accuracy=(ConfusionMatrix[0,0]+ConfusionMatrix[1,1])/sum(sum(ConfusionMatrix))\n","print('Accuracy : ',accuracy)\n","error=1-accuracy\n","print('Error: ',error)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfRU2R4gbtun"},"source":["#coefficients\n","slope1=fitted1.params[1]/(-fitted1.params[2])\n","intercept1=fitted1.params[0]/(-fitted1.params[2])\n","\n","#Finally draw the decision boundary for this logistic regression model\n","      \n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(111)\n","\n","ax1.scatter(Emp_Purchase1.Age[Emp_Purchase1.Purchase==0],Emp_Purchase1.Experience[Emp_Purchase1.Purchase==0], s=100, c='b', marker=\"o\", label='Purchase 0')\n","ax1.scatter(Emp_Purchase1.Age[Emp_Purchase1.Purchase==1],Emp_Purchase1.Experience[Emp_Purchase1.Purchase==1], s=100, c='r', marker=\"+\", label='Purchase 1')\n","\n","plt.xlim(min(Emp_Purchase1.Age), max(Emp_Purchase1.Age))\n","plt.ylim(min(Emp_Purchase1.Experience), max(Emp_Purchase1.Experience))\n","plt.legend(loc='upper left');\n","\n","x_min, x_max = ax1.get_xlim()\n","ax1.plot([0, x_max], [intercept1, x_max*slope1+intercept1],linewidth=4)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhR2SRNwcJKO"},"source":["# Non-Linear Decision Boundaries"]},{"cell_type":"code","metadata":{"id":"IRXnunIkcCeG"},"source":["#plotting the overall data\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","\n","ax.scatter(Emp_Purchase_raw.Age[Emp_Purchase_raw.Purchase==0],Emp_Purchase_raw.Experience[Emp_Purchase_raw.Purchase==0], s=100, c='b', marker=\"o\", label='Purchase 0')\n","ax.scatter(Emp_Purchase_raw.Age[Emp_Purchase_raw.Purchase==1],Emp_Purchase_raw.Experience[Emp_Purchase_raw.Purchase==1], s=100, c='r', marker=\"+\", label='Purchase 1')\n","\n","plt.xlim(min(Emp_Purchase_raw.Age), max(Emp_Purchase_raw.Age))\n","plt.ylim(min(Emp_Purchase_raw.Experience), max(Emp_Purchase_raw.Experience))\n","plt.legend(loc='upper left');\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSXu_-5BcLf2"},"source":["###Logistic Regerssion model1\n","import statsmodels.formula.api as sm\n","model = sm.logit(formula='Purchase ~ Age+Experience', data=Emp_Purchase_raw)\n","fitted = model.fit()\n","fitted.summary2()\n","\n","# getting slope and intercept of the line\n","slope=fitted.params[1]/(-fitted.params[2])\n","intercept=fitted.params[0]/(-fitted.params[2])\n","\n","#Finally draw the decision boundary for this logistic regression model\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","\n","ax.scatter(Emp_Purchase_raw.Age[Emp_Purchase_raw.Purchase==0],Emp_Purchase_raw.Experience[Emp_Purchase_raw.Purchase==0], s=100, c='b', marker=\"o\", label='Purchase 0')\n","ax.scatter(Emp_Purchase_raw.Age[Emp_Purchase_raw.Purchase==1],Emp_Purchase_raw.Experience[Emp_Purchase_raw.Purchase==1], s=100, c='r', marker=\"+\", label='Purchase 1')\n","plt.xlim(min(Emp_Purchase_raw.Age), max(Emp_Purchase_raw.Age))\n","plt.ylim(min(Emp_Purchase_raw.Experience), max(Emp_Purchase_raw.Experience))\n","plt.legend(loc='upper left');\n","\n","x_min, x_max = ax.get_xlim()\n","ax.plot([0, x_max], [intercept, x_max*slope+intercept],linewidth=4)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OUtX9fBacWMm"},"source":["# Two Intermediate Models"]},{"cell_type":"code","metadata":{"id":"JxzOnl2scSoL"},"source":["#Second model\n","Emp_Purchase2=Emp_Purchase_raw[Emp_Purchase_raw.Sample_Set>1]\n","Emp_Purchase2.shape\n","Emp_Purchase2.columns.values\n","Emp_Purchase2.head(10)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0j3V1XshcXOM"},"source":["import statsmodels.formula.api as sm\n","model2 = sm.logit(formula='Purchase ~ Age+Experience', data=Emp_Purchase2)\n","fitted2 = model2.fit()\n","print(fitted2.summary2())\n","\n","# getting slope and intercept of the line\n","# getting slope and intercept of the line\n","slope2=fitted2.params[1]/(-fitted2.params[2])\n","intercept2=fitted2.params[0]/(-fitted2.params[2])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"onkz17WNckCw"},"source":["## The Intermediate output and combined model"]},{"cell_type":"code","metadata":{"id":"6ut6MGqccaPa"},"source":["#The two new coloumns\n","Emp_Purchase_raw['inter1']=fitted1.predict(Emp_Purchase_raw[[\"Age\"]+[\"Experience\"]])\n","Emp_Purchase_raw['inter2']=fitted2.predict(Emp_Purchase_raw[[\"Age\"]+[\"Experience\"]])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V3sBev1ZcnwW"},"source":["#plotting the new columns vs Target\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","\n","ax.scatter(Emp_Purchase_raw.inter1[Emp_Purchase_raw.Purchase==0],Emp_Purchase_raw.inter2[Emp_Purchase_raw.Purchase==0], s=100, c='b', marker=\"o\", label='Purchase 0')\n","ax.scatter(Emp_Purchase_raw.inter1[Emp_Purchase_raw.Purchase==1],Emp_Purchase_raw.inter2[Emp_Purchase_raw.Purchase==1], s=100, c='r', marker=\"+\", label='Purchase 1')\n","\n","plt.xlim(min(Emp_Purchase_raw.inter1), max(Emp_Purchase_raw.inter1)+0.2)\n","plt.ylim(min(Emp_Purchase_raw.inter2), max(Emp_Purchase_raw.inter2)+0.2)\n","\n","plt.legend(loc='lower left')\n","plt.title('h1, h2 vs target ')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ycMz-NJkcv2e"},"source":["## Final Logistic Regerssion model with Intermediate outputs as input"]},{"cell_type":"code","metadata":{"id":"Fcdp-IVPcqCS"},"source":["\n","import statsmodels.formula.api as sm\n","\n","model_combined = sm.logit(formula='Purchase ~ inter1+inter2', data=Emp_Purchase_raw)\n","fitted_combined = model_combined.fit(method=\"bfgs\")\n","fitted_combined.summary()\n","\n","# getting slope and intercept of the line\n","slope_combined=fitted_combined.params[1]/(-fitted_combined.params[2])\n","intercept_combined=fitted_combined.params[0]/(-fitted_combined.params[2])\n","\n","#Finally draw the decision boundary for this logistic regression model\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","ax2 = fig.add_subplot(111)\n","\n","ax2.scatter(Emp_Purchase_raw.inter1[Emp_Purchase_raw.Purchase==0],Emp_Purchase_raw.inter2[Emp_Purchase_raw.Purchase==0], s=100, c='b', marker=\"o\", label='Purchase 0')\n","ax2.scatter(Emp_Purchase_raw.inter1[Emp_Purchase_raw.Purchase==1],Emp_Purchase_raw.inter2[Emp_Purchase_raw.Purchase==1], s=100, c='r', marker=\"+\", label='Purchase 1')\n","\n","plt.xlim(min(Emp_Purchase_raw.inter1), max(Emp_Purchase_raw.inter1)+0.2)\n","plt.ylim(min(Emp_Purchase_raw.inter2), max(Emp_Purchase_raw.inter2)+0.2)\n","\n","plt.legend(loc='lower left')\n","plt.title('h1, h2 vs target ')\n","\n","x_min, x_max = ax2.get_xlim()\n","y_min,y_max=ax2.get_ylim()\n","ax2.plot([x_min, x_max], [x_min*slope_combined+intercept_combined, x_max*slope_combined+intercept_combined],linewidth=4)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y03rQLAScydP"},"source":["#######Accuracy and error of the model1\n","#Create the confusion matrix\n","#Predciting Values\n","predicted_values=fitted_combined.predict(Emp_Purchase_raw[[\"inter1\"]+[\"inter2\"]])\n","predicted_values[1:10]\n","\n","#Lets convert them to classes using a threshold\n","threshold=0.5\n","threshold\n","\n","import numpy as np\n","predicted_class=np.zeros(predicted_values.shape)\n","predicted_class[predicted_values>threshold]=1\n","\n","#ConfusionMatrix\n","from sklearn.metrics import confusion_matrix as cm\n","ConfusionMatrix = cm(Emp_Purchase_raw[['Purchase']],predicted_class)\n","print(ConfusionMatrix)\n","accuracy=(ConfusionMatrix[0,0]+ConfusionMatrix[1,1])/sum(sum(ConfusionMatrix))\n","print(accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jAFmgdb1ddza"},"source":["## The two decison boundries"]},{"cell_type":"code","metadata":{"id":"0IDUR71hc1XB"},"source":["slope1=fitted1.params[1]/(-fitted1.params[2])\n","intercept1=fitted1.params[0]/(-fitted1.params[2])\n","\n","slope2=fitted2.params[1]/(-fitted2.params[2])\n","intercept2=fitted2.params[0]/(-fitted2.params[2])\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(111)\n","plt.rcParams[\"figure.figsize\"] = (8,6)\n","plt.title('Age, Experience  vs Purchase - Overall Data', fontsize=20)\n","\n","\n","ax1.scatter(Emp_Purchase_raw.Age[Emp_Purchase_raw.Purchase==0],Emp_Purchase_raw.Experience[Emp_Purchase_raw.Purchase==0], s=100, c='b', marker=\"o\", label='Purchase 0')\n","ax1.scatter(Emp_Purchase_raw.Age[Emp_Purchase_raw.Purchase==1],Emp_Purchase_raw.Experience[Emp_Purchase_raw.Purchase==1], s=100, c='r', marker=\"x\", label='Purchase 1')\n","ax1.set_xlabel('Age',fontsize=15)\n","ax1.set_ylabel('Experience',fontsize=15)\n","\n","plt.xlim(min(Emp_Purchase_raw.Age), max(Emp_Purchase_raw.Age))\n","plt.ylim(min(Emp_Purchase_raw.Experience), max(Emp_Purchase_raw.Experience))\n","\n","x_min, x_max = ax1.get_xlim()\n","ax1.plot([0, x_max], [intercept1, x_max*slope1+intercept1],linewidth=4,c='g')\n","ax1.plot([0, x_max], [intercept2, x_max*slope2+intercept2],linewidth=4, c='g')\n","\n","plt.legend(loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LQz_YRfBeMSk"},"source":["# Building the neural network in Py "]},{"cell_type":"markdown","metadata":{"id":"EHKo5tEgl2BR"},"source":["# Digit Recognition Example"]},{"cell_type":"code","metadata":{"id":"haLOxUEejdPk"},"source":["#Image importing\n","import matplotlib.pyplot as plt\n","import urllib.request  \n","\n","#read cat image\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/cat/cat.jpeg\", \"cat.jpeg\")\n","x=plt.imread('cat.jpeg')\n","plt.imshow(x)\n","print(\"Shape of the Image \", x.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_HQuvUKl-_Z"},"source":["print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABH1zc9Xe4m5"},"source":["!pip install neurolab\n","import neurolab as nl\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mdUdU8Ol6uK"},"source":["#Importing test and training data\n","import numpy as np\n","digits_train = np.loadtxt(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/Digit%20Recognizer/USPS/zip.train.txt\")\n","digits_test = np.loadtxt(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/Digit%20Recognizer/USPS/zip.test.txt\")\n","\n","#digits_train is numpy array. we convert it into dataframe for better handling\n","train_data=pd.DataFrame(digits_train)\n","test_data=pd.DataFrame(digits_test)\n","print(\"train_data.shape\", train_data.shape)\n","print(train_data.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"md7FyGglwN06"},"source":["#To get labels of the images\n","train_data[0].value_counts()     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fo64lFtMwkNG"},"source":["#Lets see some random images.\n","from random import randrange\n","i=randrange(7000)\n","\n","print(\"Row num\", i)\n","data_row=digits_train[i][1:]\n","pixels = np.matrix(data_row)\n","pixels=pixels.reshape(16,16)\n","plt.imshow(pixels,cmap='Greys')\n","plt.show()\n","\n","print(\"Row num\", i+100)\n","data_row=digits_train[i+100][1:]\n","pixels = np.matrix(data_row)\n","pixels=pixels.reshape(16,16)\n","plt.imshow(pixels,cmap='Greys')\n","plt.show()\n","\n","print(\"Row num\", i+200)\n","data_row=digits_train[i+200][1:]\n","pixels = np.matrix(data_row)\n","pixels=pixels.reshape(16,16)\n","plt.imshow(pixels,cmap='Greys')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0b3EjgG8zoSN"},"source":["## Data preparation"]},{"cell_type":"code","metadata":{"id":"giOwhVA5yUuJ"},"source":["X_train=train_data.iloc[:,1:]\n","X_test=test_data.iloc[:,1:]\n","y_train=train_data.iloc[:,0]\n","y_test=test_data.iloc[:,0]\n","#Shape of the data\n","print(\"X_train shape\", X_train.shape)\n","print(\"y_train shape\", y_train.shape)\n","print(\"X_test shape\", X_test.shape)\n","print(\"y_test shape\", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJ8W4oHAxiLa"},"source":["#Creating multiple binary columns for multiple outputs\n","#####We need these variables while building the model\n","digit_labels=pd.DataFrame()\n","\n","#Convert target into onehot encoding\n","digit_labels = pd.get_dummies(y_train)\n","\n","#see our newly created labels data\n","digit_labels.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXnXCCU7x8oF"},"source":["#getting minimum and maximum of each column of x_train into a list\n","min_max_all_cols=[[X_train[i][0:].min(), X_train[i][0:].max()] for i in range(1,X_train.shape[1]+1)]\n","print(len(min_max_all_cols))\n","print(min_max_all_cols)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-Sp5Sgm0d2E"},"source":["## Model Building"]},{"cell_type":"code","metadata":{"id":"97PuVPFozsvM"},"source":["##Configure the network\n","net = nl.net.newff(minmax=min_max_all_cols,size=[20,10],transf=[nl.trans.LogSig()]*2)\n","\n","#Training method is Resilient Backpropagation method\n","net.trainf = nl.train.train_rprop \n","\n","##Train the network\n","import time\n","start_time = time.time()\n","net.train(X_train, digit_labels, show=0, epochs=300)\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwHUM9vIqKIw"},"source":["'''\r\n","#minmax\t\r\n","This parameter takes a list of lists as input. \r\n","We need to supply the minimum and maximum value of all the input variables. \r\n","It helps the algorithm in weights initialization \r\n","\r\n","#Size \r\n","Takes a list as input.\r\n","Mention nodes in each layer except the input layer\r\n","[Nodes in hidden layer1, Nodes in hidden layer2,…, Nodes in hidden layer k, Nodes in output layer]\r\n","[2,1] – One hidden layer with 2 nodes and an output layer with one node\r\n","[20,10] – One hidden layer with 20 nodes and an output layer with ten nodes\r\n","\r\n","#Transf= nl.trans.LogSig()\r\n","‘Transf’ is the activation function parameter. LogSig() is the sigmoid function’s standard syntax. For regression output we can use “PureLin”\r\n","[nl.trans.LogSig()]*2\t*2 denotes the two activations from input to hidden; hidden to output in this case.\r\n","If we have two hidden layers, then we need to mention*3\r\n","\r\n","net.trainf = nl.train.train_rprop \r\n","#Train algorithms based gradients algorithms - Resilient Backpropagation\r\n","\r\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0JrIe4qN06S0"},"source":["## Model Results"]},{"cell_type":"code","metadata":{"id":"ROs2zlTDz8HZ"},"source":["# Prediction on test data\n","predicted_values = net.sim(X_test)\n","predicted=pd.DataFrame(predicted_values)\n","#print(round(predicted.head(10),3))\n","\n","#Converting predicted probabilities into numbers\n","predicted_number=predicted.idxmax(axis=1)\n","#print(predicted_number.head(15))\n","\n","##Accuracy calculation on test data\n","#confusion matrix\n","ConfusionMatrix = cm(y_test,predicted_number)\n","print(\"ConfusionMatrix on test data \\n\", ConfusionMatrix)\n","\n","#accuracy\n","accuracy=np.trace(ConfusionMatrix)/sum(sum(ConfusionMatrix))\n","print(\"Test Accuracy\", accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"feFNWFrlzzsM"},"source":["###Preictions on Random data\n","\n","#i is a random number between 0 and 7291\n","i=randrange(7291)\n","\n","random_sampel_data=digits_train[[i]]\n","random_sampel_data1=pd.DataFrame(random_sampel_data)\n","X_sample=random_sampel_data1.drop(random_sampel_data1.columns[[0]], axis=1)\n","\n","predicted_values = net.sim(X_sample)\n","predicted=pd.DataFrame(predicted_values)\n","predicted_number=predicted.idxmax(axis=1)\n","predicted_number\n","\n","data_row=random_sampel_data[0][1:]\n","pixels = np.matrix(data_row)\n","pixels=pixels.reshape(16,16)\n","plt.rcParams[\"figure.figsize\"] = (7,5)\n","plt.title([\"Row No \", i, \"Predicted Digit \", predicted_number[0]], fontsize=20)\n","plt.imshow(pixels, cmap='Greys')"],"execution_count":null,"outputs":[]}]}